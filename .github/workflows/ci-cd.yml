name: CI/CD Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

env:
  AWS_REGION: us-east-1

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Validate Workflow Files
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          for file in .github/workflows/*.yml; do
            gh workflow view "$file" >/dev/null
          done

  app-test:
    needs: validate
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Set up JDK 17
        uses: actions/setup-java@v3
        with:
          distribution: 'temurin'
          java-version: '17'
      - name: Build and Test
        run: |
          cd application
          mvn test

  app-security:
    needs: validate
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: OWASP Dependency Check Backend
        uses: dependency-check/Dependency-Check_Action@main
        env:
          JAVA_HOME: /opt/jdk
        with:
          project: "Application Backend"
          path: "application"
          format: "HTML"
          args: "--failOnCVSS 7"
      - name: OWASP Dependency Check Frontend
        uses: dependency-check/Dependency-Check_Action@main
        env:
          JAVA_HOME: /opt/jdk
        with:
          project: "Application Frontend"
          path: "application/frontend"
          format: "HTML"
          args: "--failOnCVSS 7"
      - name: Build Backend Docker Image
        run: |
          cd application
          docker build -t backend:latest .
      - name: Build Frontend Docker Image
        run: |
          cd application/frontend
          docker build -t frontend:latest .

  security-checks:
    needs: [app-test, app-security]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Run TFSec on Terraform
        uses: aquasecurity/tfsec-action@v1.0.0
        with:
          working_directory: terraform
        continue-on-error: true

      - name: Run Semgrep
        uses: returntocorp/semgrep-action@v1
        with:
          config: "auto"

      - name: Run Gitleaks
        uses: gitleaks/gitleaks-action@v2
        with:
          args: "--verbose --redact --source ."

      - name: Install Grype
        run: |
          curl -sSfL https://raw.githubusercontent.com/anchore/grype/main/install.sh | sh -s -- -b /usr/local/bin

      - name: Scan backend image with Grype
        run: |
          docker build -t backend-temp:latest ./application
          grype backend-temp:latest --fail-on high

  push-to-ecr:
    needs: security-checks
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      - name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v2
      - name: Push Backend Image
        env:
          ECR_REGISTRY: 797394900921.dkr.ecr.us-east-1.amazonaws.com
          ECR_REPOSITORY: backend-repo
          IMAGE_TAG: ${{ github.sha }}
        run: |
          cd application
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:latest
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest
      - name: Push Frontend Image
        env:
          ECR_REGISTRY: 797394900921.dkr.ecr.us-east-1.amazonaws.com
          ECR_REPOSITORY: frontend-repo
          IMAGE_TAG: ${{ github.sha }}
        run: |
          cd application/frontend
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:latest
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest

  terraform-deploy:
    needs: push-to-ecr
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: hashicorp/setup-terraform@v1
        with:
          terraform_version: 1.5.0
      - uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      - name: Get db_password from AWS SSM
        id: get-db-password
        run: |
          DB_PASSWORD=$(aws ssm get-parameter \
            --name "/terraform/db_password" \
            --with-decryption \
            --query "Parameter.Value" \
            --output text)
          echo "TF_VAR_db_password=$DB_PASSWORD" >> $GITHUB_ENV
      - name: Terraform Init & Apply
        run: |
          cd terraform
          terraform init
          terraform apply -auto-approve

  eks-deploy:
    needs: terraform-deploy
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      - uses: aws-actions/amazon-ecr-login@v2
      - name: Update kubeconfig
        run: aws eks update-kubeconfig --name digital-store-cluster --region ${{ env.AWS_REGION }}
      - name: Deploy to EKS
        env:
          IMAGE_TAG: ${{ github.sha }}
          ECR_REGISTRY: 797394900921.dkr.ecr.us-east-1.amazonaws.com
        run: |
          sed -i "s|image:.*digital-store/backend:.*|image: $ECR_REGISTRY/tristan:$IMAGE_TAG|g" k8s/backend/deployment.yaml
          sed -i "s|image:.*digital-store/frontend:.*|image: $ECR_REGISTRY/tristan-fronted:$IMAGE_TAG|g" k8s/frontend/deployment.yaml
          kubectl apply -f k8s

  terraform-cleanup:
    needs: [terraform-deploy, eks-deploy, validate-infra, wait-and-validate]
    if: ${{ always() }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - uses: hashicorp/setup-terraform@v1
        with:
          terraform_version: 1.5.0

      - uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Get db_password from AWS SSM
        run: |
          DB_PASSWORD=$(aws ssm get-parameter \
            --name "/terraform/db_password" \
            --with-decryption \
            --query "Parameter.Value" \
            --output text)
          echo "TF_VAR_db_password=$DB_PASSWORD" >> $GITHUB_ENV

      - name: Terraform Refresh & Destroy
        if: >
          ${{
            needs.terraform-deploy.result == 'failure' ||
            needs.eks-deploy.result == 'failure' ||
            needs.validate-infra.result == 'failure' ||
            needs.wait-and-validate.result == 'failure'
          }}
        run: |
          cd terraform
          terraform init
          terraform refresh || true
          terraform destroy -auto-approve || true

      - name: Fallback Cleanup for digital* resources
        if: >
          ${{
            needs.terraform-deploy.result == 'failure' ||
            needs.eks-deploy.result == 'failure' ||
            needs.validate-infra.result == 'failure' ||
            needs.wait-and-validate.result == 'failure'
          }}
        run: |
          echo "Nettoyage manuel des ressources contenant 'digital'"

          # --- EKS Clusters contenant 'digital' ---
          for CLUSTER in $(aws eks list-clusters --query "clusters[]" --output text); do
            if [[ $CLUSTER == digital* ]]; then
              echo "Suppression du cluster EKS: $CLUSTER"
              aws eks delete-cluster --name $CLUSTER || true
            fi
          done

          # --- RDS Instances contenant 'digital' ---
          for DB in $(aws rds describe-db-instances --query "DBInstances[].DBInstanceIdentifier" --output text); do
            if [[ $DB == digital* ]]; then
              echo "Suppression de l'instance RDS: $DB"
              aws rds delete-db-instance --db-instance-identifier $DB --skip-final-snapshot || true
            fi
          done

          # --- Subnet Groups RDS ---
          for SGROUP in $(aws rds describe-db-subnet-groups --query "DBSubnetGroups[].DBSubnetGroupName" --output text); do
            if [[ $SGROUP == digital* ]]; then
              echo "Suppression du DB Subnet Group: $SGROUP"
              aws rds delete-db-subnet-group --db-subnet-group-name $SGROUP || true
            fi
          done

          # --- Load Balancers ---
          for LB_ARN in $(aws elbv2 describe-load-balancers --query "LoadBalancers[?contains(DNSName, 'digital')].LoadBalancerArn" --output text); do
            echo "Suppression du load balancer: $LB_ARN"
            aws elbv2 delete-load-balancer --load-balancer-arn "$LB_ARN" || true
          done

          # --- Target Groups ---
          for TG_ARN in $(aws elbv2 describe-target-groups --query "TargetGroups[?starts_with(TargetGroupName, 'digital')].TargetGroupArn" --output text); do
            echo "Suppression du target group: $TG_ARN"
            aws elbv2 delete-target-group --target-group-arn "$TG_ARN" || true
          done

          # --- IAM Roles ---
          ROLES=$(aws iam list-roles --query "Roles[?contains(RoleName, 'digital')].RoleName" --output text)
          for ROLE in $ROLES; do
            echo "Traitement du r√¥le IAM: $ROLE"
            
            POLICIES=$(aws iam list-attached-role-policies --role-name "$ROLE" --query "AttachedPolicies[].PolicyArn" --output text)
            for POLICY_ARN in $POLICIES; do
              echo " - D√©tachement de la policy: $POLICY_ARN"
              aws iam detach-role-policy --role-name "$ROLE" --policy-arn "$POLICY_ARN" || true
            done

            INLINE_POLICIES=$(aws iam list-role-policies --role-name "$ROLE" --query "PolicyNames[]" --output text)
            for INLINE in $INLINE_POLICIES; do
              echo " - Suppression de la inline policy: $INLINE"
              aws iam delete-role-policy --role-name "$ROLE" --policy-name "$INLINE" || true
            done

            aws iam delete-role --role-name "$ROLE" || true
            echo "R√¥le $ROLE supprim√©"
          done

          echo "Fallback cleanup digital* termin√©."
